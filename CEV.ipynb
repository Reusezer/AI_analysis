{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72965259-5bc4-4082-a673-016168073704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = '<firename>",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the functions as provided in the user's code snippet\n",
    "\n",
    "def filter_columns_by_score_range_updated(columns, score_range):\n",
    "    \"\"\"Filter columns based on a given score range.\"\"\"\n",
    "    return [col for col in columns if col.split('Score')[-1].isdigit() and int(col.split('Score')[-1]) in score_range]\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def calculate_cev_updated(df, columns_range):\n",
    "    \"\"\"Calculate the Combined Error Variance (CEV) for a set of columns, without considering question numbers.\"\"\"\n",
    "    cev_scores = {}\n",
    "    \n",
    "    # Extract relevant columns\n",
    "    relevant_columns = [col for col in df.columns if \"Answer.\" in col and \"Score\" in col]\n",
    "    \n",
    "    # Filter out the 'Answer.total' columns\n",
    "    non_total_columns = [col for col in relevant_columns if \"totalScore\" not in col]\n",
    "    score_types = list(set([col.split('Score')[0].split('.')[-1] for col in non_total_columns]))\n",
    "    \n",
    "    # Filter columns related to the score range\n",
    "    filtered_columns = filter_columns_by_score_range_updated(non_total_columns, columns_range)\n",
    "    \n",
    "    # Group columns by score type (ignoring the question number)\n",
    "    columns_by_type = {score_type: [col for col in filtered_columns if f\"{score_type}Score\" in col] for score_type in score_types}\n",
    "    \n",
    "    # Calculate CEV between each pair of aspects, considering all questions within the range\n",
    "    for (type1, cols1), (type2, cols2) in itertools.combinations(columns_by_type.items(), 2):\n",
    "        scores1 = df[cols1].values.flatten()\n",
    "        scores1 = scores1[~np.isnan(scores1)]  # Remove NaN values\n",
    "        \n",
    "        scores2 = df[cols2].values.flatten()\n",
    "        scores2 = scores2[~np.isnan(scores2)]  # Remove NaN values\n",
    "        \n",
    "        combined_variance = np.var(scores1 - scores2)\n",
    "        cev_scores[(type1, type2)] = combined_variance\n",
    "    \n",
    "    return cev_scores\n",
    "\n",
    "# Since we do not have the range of the question numbers from the user,\n",
    "# We'll assume the range from the screenshot and calculate CEV for questions 1~10\n",
    "cev_scores_1_10 = calculate_cev_updated(df, range(1, 11))\n",
    "\n",
    "# Check the calculated CEV scores\n",
    "cev_scores_1_10\n",
    "\n",
    "\n",
    "def visualize_cev_as_heatmap_corrected(cev_scores, title):\n",
    "    \"\"\"Visualize CEV scores as a heatmap with empty cells for self-comparison.\"\"\"\n",
    "    aspect_pairs, cev_values = zip(*cev_scores.items())\n",
    "    aspect1, aspect2 = zip(*aspect_pairs)\n",
    "    \n",
    "    # Convert to DataFrame for visualization\n",
    "    df_cev = pd.DataFrame({'Aspect1': aspect1, 'Aspect2': aspect2, 'CEV': cev_values})\n",
    "    \n",
    "    # Fill in the missing combinations with the same values due to symmetry, excluding self-comparisons\n",
    "    df_cev_full = pd.concat([\n",
    "        df_cev,\n",
    "        pd.DataFrame({'Aspect1': aspect2, 'Aspect2': aspect1, 'CEV': cev_values})[df_cev['Aspect1'] != df_cev['Aspect2']]\n",
    "    ]).drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    df_cev_pivot = df_cev_full.pivot_table(index='Aspect1', columns='Aspect2', values='CEV', aggfunc='first')\n",
    "\n",
    "    # Get the list of aspects from the index of the pivot table\n",
    "    aspects = df_cev_pivot.index.tolist()\n",
    "\n",
    "    # Set diagonal to NaN for self-comparison\n",
    "    for aspect in aspects:\n",
    "        df_cev_pivot.loc[aspect, aspect] = np.nan\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(df_cev_pivot, annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.5, cbar_kws={\"label\": \"CEV Value\"})\n",
    "    plt.title(title)\n",
    "    plt.tight_layout() # This will adjust the plot to ensure everything fits without overlapping\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the CEV scores for questions 1~10 as a heatmap with corrected empty cells and dynamic title\n",
    "file_name_without_extension = file_path.split('/')[-1].replace('.csv', '')\n",
    "visualize_cev_as_heatmap_corrected(cev_scores_1_10, f'Combined Error Variance (CEV) for {file_name_without_extension}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fd8be4b-f215-41c0-b07f-d37f763c9092",
   "metadata": {},
    {
     "data": {
       "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "file_pat1h = '/Users/ripito/Documents/Document/5th Year TGUISS/課題研究/mturk/V3/Claude.csv'\n",
    "file_path = '/Users/ripito/Documents/Document/5th Year TGUISS/課題研究/mturk/V1/GPT3.5:BARD/GPT3.5:BARD.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the functions as provided in the user's code snippet\n",
    "\n",
    "def filter_columns_by_score_range_updated(columns, score_range):\n",
    "    \"\"\"Filter columns based on a given score range.\"\"\"\n",
    "    return [col for col in columns if col.split('Score')[-1].isdigit() and int(col.split('Score')[-1]) in score_range]\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def calculate_cev_updated(df, columns_range):\n",
    "    \"\"\"Calculate the Combined Error Variance (CEV) for a set of columns, without considering question numbers.\"\"\"\n",
    "    cev_scores = {}\n",
    "    \n",
    "    # Extract relevant columns\n",
    "    relevant_columns = [col for col in df.columns if \"Answer.\" in col and \"Score\" in col]\n",
    "    \n",
    "    # Filter out the 'Answer.total' columns\n",
    "    non_total_columns = [col for col in relevant_columns if \"totalScore\" not in col]\n",
    "    score_types = list(set([col.split('Score')[0].split('.')[-1] for col in non_total_columns]))\n",
    "    \n",
    "    # Filter columns related to the score range\n",
    "    filtered_columns = filter_columns_by_score_range_updated(non_total_columns, columns_range)\n",
    "    \n",
    "    # Group columns by score type (ignoring the question number)\n",
    "    columns_by_type = {score_type: [col for col in filtered_columns if f\"{score_type}Score\" in col] for score_type in score_types}\n",
    "    \n",
    "    # Calculate CEV between each pair of aspects, considering all questions within the range\n",
    "    for (type1, cols1), (type2, cols2) in itertools.combinations(columns_by_type.items(), 2):\n",
    "        scores1 = df[cols1].values.flatten()\n",
    "        scores1 = scores1[~np.isnan(scores1)]  # Remove NaN values\n",
    "        \n",
    "        scores2 = df[cols2].values.flatten()\n",
    "        scores2 = scores2[~np.isnan(scores2)]  # Remove NaN values\n",
    "        \n",
    "        combined_variance = np.var(scores1 - scores2)\n",
    "        cev_scores[(type1, type2)] = combined_variance\n",
    "    \n",
    "    return cev_scores\n",
    "\n",
    "# Since we do not have the range of the question numbers from the user,\n",
    "# We'll assume the range from the screenshot and calculate CEV for questions 1~10\n",
    "cev_scores_1_10 = calculate_cev_updated(df, range(11, 21))\n",
    "\n",
    "def visualize_cev_as_heatmap_corrected(cev_scores, title):\n",
    "    \"\"\"Visualize CEV scores as a heatmap with empty cells for self-comparison.\"\"\"\n",
    "    aspect_pairs, cev_values = zip(*cev_scores.items())\n",
    "    aspect1, aspect2 = zip(*aspect_pairs)\n",
    "    \n",
    "    # Convert to DataFrame for visualization\n",
    "    df_cev = pd.DataFrame({'Aspect1': aspect1, 'Aspect2': aspect2, 'CEV': cev_values})\n",
    "    \n",
    "    # Fill in the missing combinations with the same values due to symmetry, excluding self-comparisons\n",
    "    df_cev_full = pd.concat([\n",
    "        df_cev,\n",
    "        pd.DataFrame({'Aspect1': aspect2, 'Aspect2': aspect1, 'CEV': cev_values})[df_cev['Aspect1'] != df_cev['Aspect2']]\n",
    "    ]).drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    print(\"Combined Error Variance (CEV) Scores:\\n\", df_cev_full)\n",
    "    \n",
    "    df_cev_pivot = df_cev_full.pivot_table(index='Aspect1', columns='Aspect2', values='CEV', aggfunc='first')\n",
    "    \n",
    "\n",
    "    # Get the list of aspects from the index of the pivot table\n",
    "    aspects = df_cev_pivot.index.tolist()\n",
    "\n",
    "    # Set diagonal to NaN for self-comparison\n",
    "    for aspect in aspects:\n",
    "        df_cev_pivot.loc[aspect, aspect] = np.nan\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(df_cev_pivot, annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.5, annot_kws={\"size\": 20}, cbar_kws={\"label\": \"CEV Value\"})\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()  # This will adjust the plot to ensure everything fits without overlapping\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the CEV scores for questions 1~10 as a heatmap with corrected empty cells and dynamic title\n",
    "file_name_without_extension = file_path.split('/')[-1].replace('.csv', '')\n",
    "visualize_cev_as_heatmap_corrected(cev_scores_1_10, f'Combined Error Variance (CEV) for {file_name_without_extension}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2e5b55e-f4a3-4379-bedd-9aca23562a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
       "text/plain": [
       "<Figure size 1400x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "file_path = '/Users/ripito/Documents/Document/5th Year TGUISS/課題研究/mturk/V3/Claude.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def filter_columns_by_score_range_updated(columns, score_range):\n",
    "    \"\"\"Filter columns based on a given score range.\"\"\"\n",
    "    return [col for col in columns if col.split('Score')[-1].isdigit() and int(col.split('Score')[-1]) in score_range]\n",
    "\n",
    "def calculate_cev_updated(df, columns_range):\n",
    "    \"\"\"Calculate the Combined Error Variance (CEV) for a set of columns, without considering question numbers.\"\"\"\n",
    "    cev_scores = {}\n",
    "    relevant_columns = [col for col in df.columns if \"Answer.\" in col and \"Score\" in col]\n",
    "    non_total_columns = [col for col in relevant_columns if \"totalScore\" not in col]\n",
    "    score_types = list(set([col.split('Score')[0].split('.')[-1] for col in non_total_columns]))\n",
    "    filtered_columns = filter_columns_by_score_range_updated(non_total_columns, columns_range)\n",
    "    columns_by_type = {score_type: [col for col in filtered_columns if f\"{score_type}Score\" in col] for score_type in score_types}\n",
    "    \n",
    "    for (type1, cols1), (type2, cols2) in itertools.combinations(columns_by_type.items(), 2):\n",
    "        scores1 = df[cols1].values.flatten()\n",
    "        scores2 = df[cols2].values.flatten()\n",
    "        scores1 = scores1[~np.isnan(scores1)]\n",
    "        scores2 = scores2[~np.isnan(scores2)]\n",
    "        combined_variance = np.var(scores1 - scores2)\n",
    "        cev_scores[(type1, type2)] = combined_variance\n",
    "    return cev_scores\n",
    "\n",
    "cev_scores_1_10 = calculate_cev_updated(df, range(1, 11))\n",
    "\n",
    "aspect_pairs, cev_values = zip(*cev_scores_1_10.items())\n",
    "aspect1, aspect2 = zip(*aspect_pairs)  # Corrected extraction of aspect names\n",
    "df_cev = pd.DataFrame({'Aspect1': aspect1, 'Aspect2': aspect2, 'CEV': cev_values})\n",
    "df_cev_full = pd.concat([df_cev, pd.DataFrame({'Aspect1': aspect2, 'Aspect2': aspect1, 'CEV': cev_values})[df_cev['Aspect1'] != df_cev['Aspect2']]]).drop_duplicates().reset_index(drop=True)\n",
    "df_cev_pivot = df_cev_full.pivot_table(index='Aspect1', columns='Aspect2', values='CEV', aggfunc='first')\n",
    "\n",
    "# Removing diagonal for self-comparison\n",
    "for aspect in df_cev_pivot.index:\n",
    "    df_cev_pivot.loc[aspect, aspect] = np.nan\n",
    "\n",
    "# 3D Visualization\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plotting a 3D bar chart\n",
    "for i in range(len(df_cev_pivot.index)):\n",
    "    for j in range(len(df_cev_pivot.columns)):\n",
    "        if not np.isnan(df_cev_pivot.iloc[i, j]):\n",
    "            ax.bar3d(i, j, 0, 1, 1, df_cev_pivot.iloc[i, j], shade=True)\n",
    "\n",
    "ax.set_xlabel('Aspect 1')\n",
    "ax.set_ylabel('Aspect 2')\n",
    "ax.set_zlabel('CEV Value')\n",
    "ax.set_xticks(np.arange(len(df_cev_pivot.columns)))\n",
    "ax.set_xticklabels(df_cev_pivot.columns)\n",
    "ax.set_yticks(np.arange(len(df_cev_pivot.index)))\n",
    "ax.set_yticklabels(df_cev_pivot.index)\n",
    "\n",
    "plt.title(f'3D Bar Plot of CEV Scores for {file_path.split('/')[-1].replace(\".csv\", \"\")}')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "424464ea-fd74-4891-8a30-c15dcfe72fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
       "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Assignments:\n",
      "               Aspect1       Aspect2       CEV  Cluster\n",
      "0  representationBias  stereotyping  0.809796        1\n",
      "1  representationBias     relevance  0.875603        1\n",
      "2  representationBias   assumptions  0.745823        1\n",
      "3  representationBias    neutrality  0.590787        2\n",
      "4        stereotyping     relevance  0.766624        1\n",
      "5        stereotyping   assumptions  0.678138        0\n",
      "6        stereotyping    neutrality  0.788549        1\n",
      "7           relevance   assumptions  0.759200        1\n",
      "8           relevance    neutrality  0.845187        1\n",
      "9         assumptions    neutrality  0.752522        1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming df is your previously loaded DataFrame containing the data\n",
    "\n",
    "# Define functions if they are not defined\n",
    "def filter_columns_by_score_range_updated(columns, score_range):\n",
    "    return [col for col in columns if col.split('Score')[-1].isdigit() and int(col.split('Score')[-1]) in score_range]\n",
    "\n",
    "def calculate_cev_updated(df, columns_range):\n",
    "    cev_scores = {}\n",
    "    relevant_columns = [col for col in df.columns if \"Answer.\" in col and \"Score\" in col]\n",
    "    non_total_columns = [col for col in relevant_columns if \"totalScore\" not in col]\n",
    "    score_types = list(set([col.split('Score')[0].split('.')[-1] for col in non_total_columns]))\n",
    "    filtered_columns = filter_columns_by_score_range_updated(non_total_columns, columns_range)\n",
    "    columns_by_type = {score_type: [col for col in filtered_columns if f\"{score_type}Score\" in col] for score_type in score_types}\n",
    "    \n",
    "    for (type1, cols1), (type2, cols2) in itertools.combinations(columns_by_type.items(), 2):\n",
    "        scores1 = df[cols1].values.flatten()\n",
    "        scores1 = scores1[~np.isnan(scores1)]\n",
    "        scores2 = df[cols2].values.flatten()\n",
    "        scores2 = scores2[~np.isnan(scores2)]\n",
    "        combined_variance = np.var(scores1 - scores2)\n",
    "        cev_scores[(type1, type2)] = combined_variance\n",
    "    return cev_scores\n",
    "\n",
    "# Calculate CEV assuming a range of questions from 1 to 10 (modify as necessary)\n",
    "cev_scores = calculate_cev_updated(df, range(1, 11))\n",
    "\n",
    "# Prepare data for clustering\n",
    "aspect_pairs, cev_values = zip(*cev_scores.items())\n",
    "df_cev_full = pd.DataFrame(list(aspect_pairs), columns=['Aspect1', 'Aspect2'])\n",
    "df_cev_full['CEV'] = cev_values\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df_cev_full[['CEV']].values)\n",
    "\n",
    "# Determine the optimal number of clusters using the Elbow method\n",
    "inertia = []\n",
    "k_range = range(1, 10)  # Checking for 1 to 9 clusters\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(data_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plotting the Elbow Graph to find the optimal K\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(k_range, inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()\n",
    "\n",
    "# Decide on the number of clusters (e.g., 3 or 4 based on the elbow plot) and run K-means\n",
    "optimal_k = 3  # You can choose this based on the elbow plot\n",
    "kmeans_final = KMeans(n_clusters=optimal_k, random_state=0)\n",
    "df_cev_full['Cluster'] = kmeans_final.fit_predict(data_scaled)\n",
    "\n",
    "# Displaying the clusters\n",
    "print(\"Cluster Assignments:\\n\", df_cev_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0330c16-6681-4fb2-b32f-295dbceb7494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
